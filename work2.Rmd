---
title: "Attrition Classification"
author: "Syed Ehraaz Atif"
date: "2024-05-15"
output:
  html_document:
    df_print: paged
---

```{r}
library(e1071)
```

This dataset was obtained from: "https://www.kaggle.com/datasets/sakshigoyal7/credit-card-customers". The objective of the dataset is to figure out why customers are leaving (attriting), and what could be done to decrease the number of customers leaving.\
\
Here are the variables in the dataset, with necessary explanations:\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) Attrition_Flag -> whether a customer has churned or not\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) Customer_Age\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3) Gender\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4) Depdendent_Count -> number of dependents of customer\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5) Education_Level\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6) Marital_Status\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7) Income_Category\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8) Card_Category -> what type of card the customer has with the bank\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9) Months_on_book\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10) Total_Relationship_Count -> total number of relationships the customer has; what defines a "relationship" is unfortunately not mentioned in the metadata\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11) Months_Inactive_12_mon\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12) Contacts_Count_12_mon -> number of times customer has contacted the bank in the past 12 months\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;13) Credit_Limit\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;14) Total_Revolving_Bal\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15) Avg_Open_To_Buy\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;16) Total_Amt_Chng_Q4_Q1\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;17) Total_Trans_Amt\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;18) Total_Trans_Ct\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;19) Total_Ct_Chng_Q4_Q1\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;20) Avg_Utilization_Ratio\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;21) Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1 -> previous person's work, to be removed\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;23) Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2 -> previous person's work, to be removed\
\
**DATA CLEANING**

```{r}
##load data
df <- read.csv("BankChurners.csv")
head(df)
```

```{r}
##get rid of unnecessary columns
df <- df[,-c(1,22,23)]
colnames(df)
```

```{r}
##inspect variables
cols <- c(2,4,9:20)
for (i in cols) {
  boxplot(df[,i], xlab=colnames(df)[i])
}
```

```{r}
##inspect variables
unique(df$Attrition_Flag)
unique(df$Gender)
unique(df$Education_Level)
unique(df$Marital_Status)
unique(df$Income_Category)
unique(df$Card_Category)
```

Some of the categorical variables seem to have "Unknown" values, which are probably a stand-in for NA or missing values.

```{r}
##get dataset where each row has at least one "Unknown"
edu_unknown <- which(df$Education_Level == "Unknown")
marital_unknown <- which(df$Marital_Status == "Unknown")
income_unknown <- which(df$Income_Category == "Unknown")
rows_unknown <- unique(union(unique(union(edu_unknown, marital_unknown)), income_unknown))

length(rows_unknown)
```

There are 3046 observations with "Unknown" in at least one column. The total size of the dataset is ~10k observations. If all 3046 observations are removed, there would still be ~70% of the dataset leftover (about 7k observations), which should be more than enough to do any analysis or modeling.

```{r}
##take out unknowns
df2 <- df[-as.integer(rows_unknown),]
dim(df2)
```


```{r}
##convert appropriate columns to factor datatype
df2$Attrition_Flag <- factor(df2$Attrition_Flag)
df2$Gender <- factor(df2$Gender)
df2$Marital_Status <- factor(df2$Marital_Status)

df2$Education_Level <- factor(df2$Education_Level,
                              levels=c(
                                "Uneducated",
                                "High School",
                                "College",
                                "Graduate",
                                "Post-Graduate",
                                "Doctorate"
                              ), ordered=TRUE)

df2$Income_Category <- factor(df2$Income_Category,
                              levels=c(
                                "Less than $40K",
                                "$40K - $60K",
                                "$60K - $80K",
                                "$80K - $120K",
                                "$120K +"
                              ), ordered=TRUE)

df2$Card_Category <- factor(df2$Card_Category,
                            levels=c(
                              "Blue",
                              "Silver",
                              "Platinum",
                              "Gold"
                            ), ordered=TRUE)
```

```{r}
##inspect variables
barplot(height=table(df2$Attrition_Flag))
barplot(height=table(df2$Gender))
barplot(height=table(df2$Education_Level))
barplot(height=table(df2$Marital_Status))
barplot(height=table(df2$Income_Category))
barplot(height=table(df2$Card_Category))
```

Observations:\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) Many more existing customers than attrited\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) Very few divorced in comparison to married or single\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3) Very, very few non-blue card members\
\
To balance out the dataset, an equivalent number of attrited and existing customers must be sampled, as an imbalance could be problematic for any models. There should remain ~2k observations, which is a lot less than the initial 10k, but is still a sizeable amount. Additionally, the vast majority of customers have blue cards, so that variable gives negligeble information; it might be simpler to remove it entirely. Lastly, although there are imbalances in the Marital_Status variable, they are not significant enough to consider re-balancing.

```{r}
##balance out the dataset
set.seed(0)

##sample existing customers
attrited_customer_sample <- rownames(df2[df2$Attrition_Flag=="Attrited Customer",])
existing_customer_sample <- sample(rownames(df2[df2$Attrition_Flag=="Existing Customer",]),
                                   length(attrited_customer_sample))
sample_rows <- union(attrited_customer_sample, existing_customer_sample)
df3 <- df2[sample_rows,]

##exclude the card category
df3 <- df3[,-8]
```

**EDA**\
\
Now that the data is clean, we can begin to investigate relationships between the variables.

```{r}
##look for relationships
##keeping it commented out - interesting plots are displayed below

#for (i in 1:19) {
#  for (j in 1:19) {
#    if (i != j) {
#      plot(x=df3[,i], y=df3[,j], xlab=colnames(df3)[i], ylab=colnames(df3)[j])
#    }
#  }
#}
```

```{r}
##found the following relationships
plot(Gender ~ Attrition_Flag, data=df3)
plot(Income_Category ~ Attrition_Flag, data=df3)
plot(Total_Relationship_Count ~ Attrition_Flag, data=df3)
plot(Months_Inactive_12_mon ~ Attrition_Flag, data=df3)
plot(Contacts_Count_12_mon ~ Attrition_Flag, data=df3)
plot(Total_Revolving_Bal ~ Attrition_Flag, data=df3)
plot(Total_Trans_Amt ~ Attrition_Flag, data=df3)
plot(Total_Trans_Ct ~ Attrition_Flag, data=df3)
plot(Total_Ct_Chng_Q4_Q1 ~ Attrition_Flag, data=df3)
plot(Avg_Utilization_Ratio ~ Attrition_Flag, data=df3)
plot(Months_on_book ~ Customer_Age, data=df3)
plot(Income_Category ~ Gender, data=df3)
plot(Total_Relationship_Count ~ Gender, data=df3)
plot(Credit_Limit ~ Gender, data=df3)
plot(Avg_Open_To_Buy ~ Gender, data=df3)
plot(Avg_Utilization_Ratio ~ Gender, data=df3)
plot(Gender ~ Education_Level, data=df3)
plot(Total_Relationship_Count ~ Education_Level, data=df3)
plot(Dependent_count ~ Marital_Status, data=df3)
plot(Total_Relationship_Count ~ Marital_Status, data=df3)
plot(Credit_Limit ~ Income_Category, data=df3)
plot(Avg_Open_To_Buy ~ Income_Category, data=df3)
plot(Avg_Utilization_Ratio ~ Income_Category, data=df3)
plot(Avg_Open_To_Buy ~ Credit_Limit, data=df3)
plot(Avg_Utilization_Ratio ~ Credit_Limit, data=df3)
plot(Avg_Utilization_Ratio ~ Avg_Open_To_Buy, data=df3)
plot(Total_Trans_Ct ~ Total_Trans_Amt, data=df3)
```

Interesting notes (things that were interesting and were not obvious or self-explanatory):\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) even though females occupy higher income categories as well, they have a lower median credit limit than males\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) average utilization ratio DECREASES as credit limit INCREASES -> very strange\
\
Although there are other relationships as well, the main objective of the dataset is to figure out how to decrease customer churn. For this reason, only relationship where Attrition_Flag is the response variable will be modeled. Of the relationships depicted above, Total_Revolving_Bal and Avg_Utilization_Ratio will be excluded because they are self-explanatory. Total_Trans_Ct will also be excluded because it is collinear to Total_Trans_Amt.

```{r}
##make a model investigating relationships to Attrition_Flag
model_1 <- glm(Attrition_Flag ~ Gender +
                 Income_Category +
                 Total_Relationship_Count +
                 Months_Inactive_12_mon +
                 Contacts_Count_12_mon +
                 Total_Trans_Amt +
                 Total_Ct_Chng_Q4_Q1, data=df3, family="binomial")
```

```{r}
##investigate model significance
model_null <- glm(Attrition_Flag ~ 1, data=df3, family="binomial")
anova(model_null, model_1, test="Chisq")
```

The model seems statistically significant at 5%.

```{r}
##investigate significance of coefficients
confint(model_1)
```

It seems like at a 5% significance level, the intercept, the third income category ("\$60K - \$80K"), Total_Relationship_Count, Months_Inactive_12_mon, Contacts_Count_12_mon, and Total_Ct_Chng_Q4_Q1 are statistically significant.\
\
Since the model and some of the coefficients are statistically significant, the coefficients can now be interpreted.

```{r}
summary(model_1)
```

The intercept indicates that when controlling for other variables, a customer is 0.32 times as likely to be existing versus attrited. If the customer is in the "\$60K - \$80K" income category, then that likelihood increases by 0.68. As the total relationship count increases by one relationship, then the customer's likelihood to be attrited increases by 1.3. For every additional month a customer is inactive, the likelihood increases by a factor of 0.61. As the number of contacts within the past 12 months increases by 1, the likelihood increases by 0.58. As the total transaction amount increases by 1, the likelihood stays about the same. Finally, as the total number of changes from Q4 to Q1 increase by 1, the likelihood increases by a factor of 31.7.\
\
**MODELING**\
\
Now that there is some information about which variables are most important for determining customer churn, a predictive model can be built.

```{r}
##scale variables
df4 <- apply(df3[,-c(1,3,5,6,7)], FUN=scale, MARGIN=2)
df4 <- cbind(df4, df3[,c(1,3,5,6,7)])

##split train and test sets
set.seed(0)
train_size <- as.integer(nrow(df4) * 0.7)
train_index <- sample(1:nrow(df4), train_size)
train <- df4[train_index,]
test <- df4[-train_index,]
```

```{r}
##test initial model's predictive power
model_2 <- glm(Attrition_Flag ~ Gender +
                 Income_Category +
                 Total_Relationship_Count +
                 Months_Inactive_12_mon +
                 Contacts_Count_12_mon +
                 Total_Trans_Amt +
                 Total_Ct_Chng_Q4_Q1, data=train, family="binomial")

preds <- predict(model_2, newdata=test, type="response")
preds[preds<0.5] <- "Attrited Customer"
preds[preds>=0.5] <- "Existing Customer"
table(test$Attrition_Flag, preds)
```

The model is not good; it only predict existing customers. It was unable to form a proper decision boundary.

```{r}
##try all predictors accounting for multicollinearity
model_3 <- glm(Attrition_Flag ~ . - Customer_Age - Credit_Limit, data=train, family="binomial")
anova(model_3, model_2, test="Chisq")
```

The model seems better than the previous one.

```{r}
preds <- predict(model_3, newdata=test, type="response")
preds[preds<0.5] <- "Attrited Customer"
preds[preds>=0.5] <- "Existing Customer"
table(test$Attrition_Flag, preds)
```

There is no improvement in the performance, unfortunately. After using all predictors, the next step would be to use tranformations (ex. Months_on_book^2). One easy way to do that would be to instead use an SVM with a non-linear kernel (radial is what is used most often).

```{r}
##try SVM using the initial variables
model_4 <- svm(Attrition_Flag ~ Gender +
                 Income_Category +
                 Total_Relationship_Count +
                 Months_Inactive_12_mon +
                 Contacts_Count_12_mon +
                 Total_Trans_Amt +
                 Total_Ct_Chng_Q4_Q1, data=train, kernel="radial", scale=FALSE)

summary(model_4)
```


```{r}
##test the predictive power
preds <- predict(model_4, newdata=test)
table(test$Attrition_Flag, preds)
```


```{r}
##try SVM with all variables
model_5 <- svm(Attrition_Flag ~ . - Customer_Age - Credit_Limit, data=train, kernel="radial", scale=FALSE)
summary(model_5)
```

```{r}
##make confusion matrix for SVM
preds <- predict(model_5, newdata=test)
table(test$Attrition_Flag, preds)
```

Now, a minimal predictive model will be built - maximizing the predictive power while minimizing the number of predictors used. Not only will this help identify which variables are most important for predicting customer churn, but it makes real life applications easier. If an accurate prediction can be made with as little predictors as possible, then the number of use cases in which the model can be used increases, as it becomes more generalized.

```{r}
##perform backward step-wise feature selection using misclassification rate
pred_cols <- c(2:6, 8:14, 16:19)
removed <- c()
formula <- "Attrition_Flag ~ ."
errors <- c()
while (length(pred_cols) > 0) {
  worst_predictor <- NULL
  worst_error <- 1
  for (col in pred_cols) {
    col_name <- colnames(train)[col]
    test_formula <- paste(formula, "-", col_name)
    model_svm <- svm(formula(test_formula), data=train, kernel="radial", scale=FALSE)
    preds <- predict(model_svm, newdata=test)
    error <- mean(preds != test$Attrition_Flag)
    
    if (error < worst_error) {
      worst_predictor <- col
      worst_error <- error
    }
  }
  
  remove <- pred_cols[which(pred_cols==worst_predictor)]
  pred_cols <- pred_cols[-which(pred_cols==worst_predictor)]
  removed <- c(removed, remove)
  formula <- paste(formula, "-", colnames(train)[remove])
  errors <- c(errors, worst_error)
}
```

```{r}
##plot the errors to look for trends
plot(errors, type="o")
```

It seems like the misclassification rate is quite low even after removing 10 predictors, after which the error starts to increase exponentially.

```{r}
first_10 <- removed[1:10]
colnames(train)[first_10]
```

By removing these 10 predictors, there should be an accurate model while minimizing the misclassification rate. Which means that the following predictors:

```{r}
colnames(train)[-first_10]
```

are the most important, excluding Customer_Age and Credit_Limit due to multicollinearity, and Attrition_Flag for obvious reasons.\

```{r}
##construct new model with "important" predictors
model_6 <- svm(Attrition_Flag ~ Months_Inactive_12_mon + 
                 Total_Revolving_Bal + 
                 Total_Amt_Chng_Q4_Q1 + 
                 Total_Trans_Amt + 
                 Total_Trans_Ct + 
                 Total_Ct_Chng_Q4_Q1, data=train, kernel="radial", scale=FALSE)

summary(model_6)
```

```{r}
##construct confusion matrix
preds <- predict(model_6, newdata=test)
table(test$Attrition_Flag, preds)
```

This model has the following metrics:\
Accuracy: 91%\
Misclassification Rate: 9%\
Precision: 93%\
Recall: 89%\
\
By all metrics, the model is very good.\
\
**CONCLUSION**\
\
The purpose of this dataset was to determine why customers were churning. According to this objective, the following variables were found to have relationships with customer churn:\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) Gender\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) Income_Category\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3) Total_Relationship_Count\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4) Months_Inactive_12_mon\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5) Contacts_Count_12_mon\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6) Total_Revolving_Bal\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7) Total_Trans_Amt\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8) Total_Trans_Ct\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9) Total_Ct_Chng_Q4_Q1\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10) Avg_Utilization_Ratio\
While the relationship certain predictors had with customer churn was self-explanatory (namely: Total_Revolving_Bal, Total_Trans_Ct, and Avg_Utilization_Ratio), the following numerical relationships between the other predictors and customer churn were found:\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) the intercept indicates that when controlling for other variables, a customer is 0.32 times as likely to be existing versus attrited\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) if the customer is in the "\$60K - \$80K" income category, then that likelihood increases to 0.68 times as likely\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3) as the total relationship count increases by one relationship, then the customer's likelihood to be attrited increases by 1.3\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4) for every additional month a customer is inactive, the likelihood increases by a factor of 0.61.\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5) as the number of contacts within the past 12 months increases by 1, the likelihood increases by 0.58.\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6) as the total transaction amount increases by 1, the likelihood stays about the same\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7) as the total number of changes from Q4 to Q1 increase by 1, the likelihood increases by a factor of 31.7\
When trying to build a predictive model, a method similar to "backward step-wise feature selection" was used, with misclassification rate as the comparison metric to try and see which predictors were crucial to predicting customer churn. The following predictors were found to be the most useful:\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) Months_Inactive_12_mon\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) Total_Revolving_Bal\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3) Total_Amt_Chng_Q4_Q1\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4) Total_Trans_Amt\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5) Total_Trans_Ct\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6) Total_Ct_Chng_Q4_Q1\
Notably, these predictors are a near-subset of the predictors that were initially found to have the strongest relationships with customer churn. The only exception is Total_Amt_Chng_Q4_Q1, but that is not too surprising as it is probably related to Total_Ct_Chng_Q4_Q1.